<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://joelstrouts.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://joelstrouts.com/" rel="alternate" type="text/html" /><updated>2019-08-21T09:51:23+08:00</updated><id>https://joelstrouts.com/</id><title type="html">Joel Strouts</title><subtitle>My personal website.
</subtitle><author><name>Joel Strouts</name></author><entry><title type="html">Memory</title><link href="https://joelstrouts.com/2019/08/20/Memory.html" rel="alternate" type="text/html" title="Memory" /><published>2019-08-20T00:00:00+08:00</published><updated>2019-08-20T00:00:00+08:00</updated><id>https://joelstrouts.com/2019/08/20/Memory</id><content type="html" xml:base="https://joelstrouts.com/2019/08/20/Memory.html">&lt;p&gt;&lt;img src=&quot;/images/hk/black-min.jpg&quot; alt=&quot;black&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I can picture the rows of hedges, rolling hills, and oak trees back home - but whether such things really exist, I have begun to doubt. Just like the existence of this place of thick crowds, thick air, and everywhere tall dirty buildings seemed so unlikely when it was a question of imagination a few months ago. They are so different, the presence of one erodes the plausibility of the other. What’s most perverse is not that England now seems fictitious, but the absolute certainty with which the natural order of things will be restored - I will again know my oak trees, and my rolling hills, and so instead it will be the here and now that seems implausible. This table, the lingering smell of vinegar that started a few minutes ago, the fact that it is sweltering hot even in the dead of night. I will go home and these things will become foggy memories. Was it really that hot? How can a smell of vinegar just abruptly start? The more time passes the more unquestionable truth is replaced by just questions. And of course you can document thoroughly, take photos, record temperatures (the &lt;em&gt;feels like&lt;/em&gt; temperature here, right now, at 5AM, is supposedly 34° - I just checked) but that rather misses the point. It’s not that I don’t know what England is like, photos don’t challenge the memory they just reassert it, but knowledge does not bring England here, and it won’t bring this moment back home.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/yellow-min.jpg&quot; alt=&quot;yellow&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s always like that though. Even in just the one place. Every year in summer I think how strange it is that it was once winter. Every time I’m ill, good health is mockingly incomprehensible. This failing of the imagination, a hard limit on the number of realities you can hold in mind (no more than one at a time) is mostly quaint. Don’t you know that things go in cycles? So what if winter sounds like a sort of joke, (you’re telling me this same sun, now oppressively hot, will become harsh and bitter cold, and these green trees will turn to looming wooden skeletons? I just don’t buy it) you will see it with your own eyes soon and summer will be the joke instead. A clockwork forgetfulness, even a little humorous. Humorous, that is, until you want to cling on to something, and something that won’t just come back around like the hands on a clock.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/car-min.jpg&quot; alt=&quot;car&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Childhood is the first of these losses. You only have it once, you pay little attention, and then it’s gone. Gone with mine is the memory of childhood holidays, which were often to the seaside, often to Guernsey. One detail that remains is of a game that I loved to play as the tide came in. My sister and I would work together, starting hours before the approach begun, digging trenches and erecting walls. Fortifying and establishing our own little enclave backed up against the sea wall - our goal: to keep out the rising tide for long as possible. What begins as a very thoughtful architectural consideration quickly becomes frantic and hopeless - but great fun. Strangely my memory of this is entirely from a birds eye perspective, as if it is not my memory but my parents. Looking down from the promenade, cheering us on as we successfully diverted a minor flooding, or survived a breaking wave. It’s funny remembering that game, because now it seems like the perfect metaphor for trying to preserve the memory of a fleeting moment. It’s hopeless. Photos, essays, souvenirs - they are your fortifications and they do hold back the tide a little while longer, but with plodding wrath the sea foam approaches. Fighting the tide is symbolic, not effective. It’s something you do for sport, for honour, not to win. The high water mark is feet above your head and no cleverness of sand architecture will stop it from being reached. Soon you have to leave your enclave lest you are washed away yourself, and you will look down from the promenade at the place you saved for a minute longer, now no more than eddies.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/blue-min.jpg&quot; alt=&quot;blue&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So when you’re fond of sand beneath you, and the tide bears down, what do you do? Do you have to fight? Half of me thinks fighting misses the point anyway. If you spend all your time worrying about the rising sea you can’t enjoy playing on the beach. By always focusing on whether you’ll remember something perhaps you prematurely switch your perspective from that of the child playing, to the parent up watching on the promenade. Living your life in birds eye rather than at ground level. Should you wander the beach and collect shells instead of building sandcastles? Perhaps there will be some peace and serenity in just accepting that your footprints are washed away. There’s something seductive about the idea. That the sea does not rage, but smooths. For every enclave eroded, a whole expanse of fresh sand is deposited. The tide is a gift, a blank canvas! But reality is not so serene I think. Beautiful memories are not lapped at but affronted. Not gracefully broken down but defaced. That awful burden of having to communicate things you don’t have words for. I’ll go home and each time I’m asked what it was like being here I’ll refine my response. That first attempt at a faithful summary will slowly become tighter and wittier, and all the same more untrue. Then all the slight mischaracterisations, made because they played better to others ears, will end up warping my own memory. What mattered to the people who probed about your experience becomes confused with what mattered to you when it actually happened. This warping is made all the more frustrating because you can’t help your own part in it. You vandalise your own memories and there’s no helping it. Soon enough the person who experienced that moment is a stranger anyway.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/rich-min.jpg&quot; alt=&quot;rich&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’m reading Anna Karenina at the moment and there are many lovely things about it. It’s a long book, and to get away with being a long book it has to have good language separate from having a good plot - and it does. I can think of two times when an expression, a particular way of phrasing something, has really stuck with me. One is in this book, and the other was from the film ‘Let The Right One In’. In both cases the expression is nothing grand, just something simply put, but put right. In the film it’s when one character asks the other if they want to ‘go steady’, as in ‘to go out with’. In England we say two people in a relationship are ‘going out with each other’ and you express your interest in someone by saying ‘do you want to go out?’ (at least you would in secondary school, flirtation is a bit more, or less, subtle after that). I always thought that saying ‘do you want to go out?’ sounded really stupid, and when I heard that expression - to go steady - in the film, I thought it was lovely and so much better. In the book the phrase that stuck with me is (on a couple occasions when the characters have wordlessly understood each other) it says ‘[they understood it] in the right way’. When one has perhaps put their foot in their mouth a little bit but that didn’t obstruct the commutation of the deeper point. It was understood &lt;em&gt;in the right way&lt;/em&gt;. I like these phrases even more because in both cases the original work was not actually in English, it is the translations that contained the lovely phrases. Funny too, because translation itself is the act of trying to understand things ‘in the right way’.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/lego-min.jpg&quot; alt=&quot;lego&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And I think this is the real answer for what to do with that patch of sand you wish you could protect from the tide. Wanting to remember tomorrow, the events of today is a conversation you have with your future self. You carry out your half of the conversation with the photos you take, notes you make, and stories you tell. He carries out his part in how he takes the meanings of those things. The best you can do is accept that you will put your foot in your mouth a little bit and just hope that the stranger in the future takes your meaning in the right way. Words are duplicitous, pictures are deceitful, but you hope that there is some essential kernel of truth that, truly understood now, will be truly understood later. It’s made more hopeful by the fact that the stranger is also technically yourself.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/distorted-min.jpg&quot; alt=&quot;distorted&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Even so, I will miss Hong Kong, and I know I won’t really be able to get this moment back, even if upon re-reading the stranger takes this message in the right way. I know that because thinking about this makes me dwell on all the other moments I’ve had that I can’t get back. Trying to reassemble that reality feels as useless as trying to place every grain of sand back where it was yesterday. It is blue, but with sorrow comes a gratitude for what is passed. The special and the temporary together will always be bitter-sweet. Sometimes fighting the tide is a game, but this time I am seeing it all in birds eye too soon and resent the sea for its policy of no exceptions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/hk/green-min.jpg&quot; alt=&quot;rich&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See you soon England.&lt;/p&gt;</content><author><name>Joel Strouts</name></author><summary type="html">I can picture the rows of hedges, rolling hills, and oak trees back home - but whether such things really exist, I have begun to doubt. Just like the existence of this place of thick crowds, thick air, and everywhere tall dirty buildings seemed so unlikely when it was a question of imagination a few months ago. They are so different, the presence of one erodes the plausibility of the other. What’s most perverse is not that England now seems fictitious, but the absolute certainty with which the natural order of things will be restored - I will again know my oak trees, and my rolling hills, and so instead it will be the here and now that seems implausible. This table, the lingering smell of vinegar that started a few minutes ago, the fact that it is sweltering hot even in the dead of night. I will go home and these things will become foggy memories. Was it really that hot? How can a smell of vinegar just abruptly start? The more time passes the more unquestionable truth is replaced by just questions. And of course you can document thoroughly, take photos, record temperatures (the feels like temperature here, right now, at 5AM, is supposedly 34° - I just checked) but that rather misses the point. It’s not that I don’t know what England is like, photos don’t challenge the memory they just reassert it, but knowledge does not bring England here, and it won’t bring this moment back home. It’s always like that though. Even in just the one place. Every year in summer I think how strange it is that it was once winter. Every time I’m ill, good health is mockingly incomprehensible. This failing of the imagination, a hard limit on the number of realities you can hold in mind (no more than one at a time) is mostly quaint. Don’t you know that things go in cycles? So what if winter sounds like a sort of joke, (you’re telling me this same sun, now oppressively hot, will become harsh and bitter cold, and these green trees will turn to looming wooden skeletons? I just don’t buy it) you will see it with your own eyes soon and summer will be the joke instead. A clockwork forgetfulness, even a little humorous. Humorous, that is, until you want to cling on to something, and something that won’t just come back around like the hands on a clock. Childhood is the first of these losses. You only have it once, you pay little attention, and then it’s gone. Gone with mine is the memory of childhood holidays, which were often to the seaside, often to Guernsey. One detail that remains is of a game that I loved to play as the tide came in. My sister and I would work together, starting hours before the approach begun, digging trenches and erecting walls. Fortifying and establishing our own little enclave backed up against the sea wall - our goal: to keep out the rising tide for long as possible. What begins as a very thoughtful architectural consideration quickly becomes frantic and hopeless - but great fun. Strangely my memory of this is entirely from a birds eye perspective, as if it is not my memory but my parents. Looking down from the promenade, cheering us on as we successfully diverted a minor flooding, or survived a breaking wave. It’s funny remembering that game, because now it seems like the perfect metaphor for trying to preserve the memory of a fleeting moment. It’s hopeless. Photos, essays, souvenirs - they are your fortifications and they do hold back the tide a little while longer, but with plodding wrath the sea foam approaches. Fighting the tide is symbolic, not effective. It’s something you do for sport, for honour, not to win. The high water mark is feet above your head and no cleverness of sand architecture will stop it from being reached. Soon you have to leave your enclave lest you are washed away yourself, and you will look down from the promenade at the place you saved for a minute longer, now no more than eddies. So when you’re fond of sand beneath you, and the tide bears down, what do you do? Do you have to fight? Half of me thinks fighting misses the point anyway. If you spend all your time worrying about the rising sea you can’t enjoy playing on the beach. By always focusing on whether you’ll remember something perhaps you prematurely switch your perspective from that of the child playing, to the parent up watching on the promenade. Living your life in birds eye rather than at ground level. Should you wander the beach and collect shells instead of building sandcastles? Perhaps there will be some peace and serenity in just accepting that your footprints are washed away. There’s something seductive about the idea. That the sea does not rage, but smooths. For every enclave eroded, a whole expanse of fresh sand is deposited. The tide is a gift, a blank canvas! But reality is not so serene I think. Beautiful memories are not lapped at but affronted. Not gracefully broken down but defaced. That awful burden of having to communicate things you don’t have words for. I’ll go home and each time I’m asked what it was like being here I’ll refine my response. That first attempt at a faithful summary will slowly become tighter and wittier, and all the same more untrue. Then all the slight mischaracterisations, made because they played better to others ears, will end up warping my own memory. What mattered to the people who probed about your experience becomes confused with what mattered to you when it actually happened. This warping is made all the more frustrating because you can’t help your own part in it. You vandalise your own memories and there’s no helping it. Soon enough the person who experienced that moment is a stranger anyway. I’m reading Anna Karenina at the moment and there are many lovely things about it. It’s a long book, and to get away with being a long book it has to have good language separate from having a good plot - and it does. I can think of two times when an expression, a particular way of phrasing something, has really stuck with me. One is in this book, and the other was from the film ‘Let The Right One In’. In both cases the expression is nothing grand, just something simply put, but put right. In the film it’s when one character asks the other if they want to ‘go steady’, as in ‘to go out with’. In England we say two people in a relationship are ‘going out with each other’ and you express your interest in someone by saying ‘do you want to go out?’ (at least you would in secondary school, flirtation is a bit more, or less, subtle after that). I always thought that saying ‘do you want to go out?’ sounded really stupid, and when I heard that expression - to go steady - in the film, I thought it was lovely and so much better. In the book the phrase that stuck with me is (on a couple occasions when the characters have wordlessly understood each other) it says ‘[they understood it] in the right way’. When one has perhaps put their foot in their mouth a little bit but that didn’t obstruct the commutation of the deeper point. It was understood in the right way. I like these phrases even more because in both cases the original work was not actually in English, it is the translations that contained the lovely phrases. Funny too, because translation itself is the act of trying to understand things ‘in the right way’. And I think this is the real answer for what to do with that patch of sand you wish you could protect from the tide. Wanting to remember tomorrow, the events of today is a conversation you have with your future self. You carry out your half of the conversation with the photos you take, notes you make, and stories you tell. He carries out his part in how he takes the meanings of those things. The best you can do is accept that you will put your foot in your mouth a little bit and just hope that the stranger in the future takes your meaning in the right way. Words are duplicitous, pictures are deceitful, but you hope that there is some essential kernel of truth that, truly understood now, will be truly understood later. It’s made more hopeful by the fact that the stranger is also technically yourself. Even so, I will miss Hong Kong, and I know I won’t really be able to get this moment back, even if upon re-reading the stranger takes this message in the right way. I know that because thinking about this makes me dwell on all the other moments I’ve had that I can’t get back. Trying to reassemble that reality feels as useless as trying to place every grain of sand back where it was yesterday. It is blue, but with sorrow comes a gratitude for what is passed. The special and the temporary together will always be bitter-sweet. Sometimes fighting the tide is a game, but this time I am seeing it all in birds eye too soon and resent the sea for its policy of no exceptions. See you soon England.</summary></entry><entry><title type="html">Iterated Function Systems / Crayon Impressions of Leaves</title><link href="https://joelstrouts.com/2019/07/30/IFS.html" rel="alternate" type="text/html" title="Iterated Function Systems / Crayon Impressions of Leaves" /><published>2019-07-30T00:00:00+08:00</published><updated>2019-07-30T00:00:00+08:00</updated><id>https://joelstrouts.com/2019/07/30/IFS</id><content type="html" xml:base="https://joelstrouts.com/2019/07/30/IFS.html">&lt;p&gt;I am about half way through my time working here and I have reached a crucial turning point in my research. All this time the goal has been to make progress on the reverse engineering problem, but it was first necessary to familiarise myself with the forward-engineering. I am &lt;em&gt;now&lt;/em&gt; familiar with that forward-engineering. In this post I sum up what I’ve learned and embellish the descriptions with pretty outputs from the program I wrote.&lt;/p&gt;

&lt;!-- more --&gt;
&lt;blockquote&gt;
  &lt;p&gt;Note: if you’re not drawn in by technical details, don’t go! Skip to &lt;a href=&quot;#the-image-generation-process-presented-interactively-and-step-by-step&quot;&gt;the interactive demonstration&lt;/a&gt; I’m very proud of it! Maybe the details will be more interesting after some intriguing pictures.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There’s this one detail about the creation of these fractal images that really confused me to begin with (and still to an extent now, although familiarity softens much frustration), and that’s what I’d like to talk about here. It’s this mismatch between the theory as I understood it, and the actual methods used in practice which didn’t seem at all related to that theory.&lt;/p&gt;

&lt;p&gt;Here’s how I originally understood the process used to generate reproductions of fractal images:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;these fractals have smaller copies of themselves embedded within themselves&lt;/li&gt;
  &lt;li&gt;if you specified the exact way that the copies were embedded, then you could reproduce the image by repeatedly making copies according to that rule&lt;/li&gt;
  &lt;li&gt;For example: if you started with the stem of the fern, then copying it around over and over again, making smaller and smaller copies of that one stem, you would end up with a skeletal model of the same fern that - after enough iterations - would look just like the original.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My reading on the topic of IFS fractals has informed me that this conception is not quite in line with the common formal definition. This is the gist of the mathematical formulation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rules for how to make copies define a ‘contraction’ on the input space. (this is the formal way of saying the copies must be &lt;em&gt;smaler&lt;/em&gt; than the original region, which makes intuitive sense because if that was not the case the process would grow outwards endlessly rather than settling down inwardly)&lt;/li&gt;
  &lt;li&gt;the visual form we call the ‘fractal’ corresponds to the set of all points that are invariant under this contraction. ie. After applying all the rules, if the resulting set of points is identical to the set you started with then that set was invariant under the contraction, so you have identified the fractal set, called the attractor.&lt;/li&gt;
  &lt;li&gt;this set of points is called the ‘attractor’ because no matter the region you start with, the application of the contraction rule always reduces the difference between the input region and the fractal set (an observation which can formalised by defining a distance function on the set of all compact regions in the space; the Hausdorf distance).&lt;/li&gt;
  &lt;li&gt;It is therefore possible to generate an image of the attractor by choosing some reasonable starting set then repeatedly applying the contraction to that region until its form has mangled into one that ceases to change significantly on further contractive iterations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now &lt;em&gt;that&lt;/em&gt; is all well and good, but here’s the screwy thing: the method for generating these images is nothing like either of those descriptions. Nothing like it.&lt;/p&gt;

&lt;p&gt;I’m going to describe the actual method which is used in detail so hopefully you can understand how strange it is.&lt;/p&gt;

&lt;h2 id=&quot;making-the-rules&quot;&gt;Making the rules&lt;/h2&gt;
&lt;p&gt;The idea of ‘contractions’ on the input space is a powerful one because it is not very prescriptive about the sorts of functions we have to use as transformation rules. It just enforces this intuitively reasonable notion that the repeated application of the rule has to result in a settling down not a blowing up. We will not work with this very general notion however, we are going to focus on one specific type of transformation which is particularly well suited to characterising fractal images as we are familiar with them: &lt;strong&gt;Affine&lt;/strong&gt; transformations. Let’s define that term.&lt;/p&gt;

&lt;p&gt;A transformation is a rule that tells us how to move around different points based on their position. Once we know how to move individual points around we can then ask what happens to every point within a shape or region to see how it warps space at a more macro level.&lt;/p&gt;

&lt;p&gt;A rule that says ‘all points move to the position $(4,3)$’ is a perfectly good example of a transformation.&lt;/p&gt;

&lt;p&gt;A rule that says ‘multiply the $x$ coordinate by two’ is also a perfectly good transformation.&lt;/p&gt;

&lt;p&gt;They can be as simple or as complex as you like, so long as the definition is unambiguous for every input position.&lt;/p&gt;

&lt;p&gt;Transformation that completely mangles any input region into something unrecognisable will not be much use for describing fractal &lt;em&gt;self similarity&lt;/em&gt;. We choose affine transformations to work with then because, like the name implies, while they may warp their input regions, the resulting outputs always share an &lt;em&gt;affinity&lt;/em&gt; with the corresponding inputs.&lt;/p&gt;

&lt;p&gt;Each affine transformation can be uniquely specified by the way it morphs a rectangle in the input space to a parallelogram of some description in the output space, so you can think of affine transformations as encompassing all of: shifting, scaling (not necessarily by the same amount in each direction), and rotating. Mathematically speaking, they are given by the composition of a linear transformation and a translation:&lt;/p&gt;

&lt;!-- TODO: it would be cool to add a little interactive thing that lets you select input region and output region and see how the resulting affine transformation maps points/regions/looks as represented with a matrix and translation vector --&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
f(\,\underline{x}\,)=\color{lightgreen}{\begin{bmatrix}a &amp; b \\ c &amp; d\end{bmatrix}}\begin{bmatrix}x\\y\end{bmatrix} + \color{orange}{\begin{bmatrix}e \\ f\end{bmatrix}} %]]&gt;&lt;/script&gt;

&lt;p&gt;Where the light green matrix is the linear part of the composition, and the orange vector is the translation vector.&lt;/p&gt;

&lt;p&gt;The translation does nothing more than move the region from one location to another, whereas the linear transformation captures all of the squishing and rotating.&lt;/p&gt;

&lt;h2 id=&quot;using-the-rules&quot;&gt;Using the Rules&lt;/h2&gt;
&lt;p&gt;That’s the bit which every conception of these IFS fractals agrees on. Affine transformations characterise the fractal. So you’ve settled on your copying rules, how do you draw a picture with them? The formal method outlined above says start with some other region then just keep morphing it with your rules over and over until it looks right. Pleasantly clean in its conception but somewhat of a pain computationally, to have to apply the function for &lt;em&gt;every single point&lt;/em&gt; in some region. Here’s what’s actually done:&lt;/p&gt;

&lt;h3 id=&quot;the-image-generation-process-presented-interactively-and-step-by-step&quot;&gt;The Image generation process, presented interactively and step by step:&lt;/h3&gt;

&lt;!-- 
  TODO:
  - add final slide with interactive options for controlling
  all parameters
  - add feature to reveal report on previously loaded system of
  equations on hover
  - make resolution not depend on computed width, more pixels can suuurely fit on the screen damnit!
--&gt;
&lt;!-- contains the whole bit to be embedded in the page --&gt;
&lt;div style=&quot;background-color: #f5f5f5; padding: 20px; border-radius: 2.1rem; border: 1px solid #4141ff&quot;&gt;
  &lt;!-- contains the visualisations --&gt;
  &lt;div id=&quot;canvas-container&quot; hidden=&quot;true&quot; style=&quot;margin-bottom: 0.5rem&quot;&gt;
  &lt;/div&gt;
  &lt;!-- contains report on last generation --&gt;
  &lt;div id=&quot;report&quot;&gt;&lt;/div&gt;
  &lt;!-- contains the buttons --&gt;
  &lt;div id=&quot;presets&quot;&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Barnsley Fern&quot; alt=&quot;barnsleyFern&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Maple Leaf&quot; alt=&quot;mapleLeaf&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Binary Tree&quot; alt=&quot;binaryTree&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Serpinski&quot; alt=&quot;serpinski&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Sand Dollar&quot; alt=&quot;sandDollar&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Random&quot; alt=&quot;random&quot; /&gt;
  &lt;/div&gt;
  &lt;!-- contains the textual desctiption --&gt;
  &lt;h4 id=&quot;frame-title&quot;&gt;↑ Select one of the above predefined rule sets to apply procedure to ↑&lt;/h4&gt;
  &lt;div id=&quot;slide-controls&quot; hidden=&quot;true&quot;&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;previous slide&quot; id=&quot;previous-button&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;next slide&quot; id=&quot;next-button&quot; /&gt;
  &lt;/div&gt;
  &lt;div id=&quot;frame-description-container&quot;&gt;
  &lt;p style=&quot;padding: 0.5rem 1rem; border-top: 1px solid #333333; font-size: 1.1em;&quot; id=&quot;frame-description&quot;&gt;&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;!-- all the logic/ content to include in that scaffold --&gt;

&lt;!-- data to be interacted with --&gt;
&lt;script&gt;
  let frames = [
    { // 0
      title:
      &quot;The final result of the image generation process.&quot;,
      description:
      'This is what we are going to build up to - the final result. The only information needed to generate this image is knowledge of the self-similar transformations that characterise it. How exactly is knowledge of these transformations applied to produce such an image though? That is what we are going to walk through step by step in this slideshow.',
      imageData: () =&gt; IFS.get(eval(preset), 250000),
    },
    { // I
      title:
      &quot;I. The initial starting point&quot;,
      description:
      &quot;We start with just one point. For simplicity's sake, the coordinates of this point are chosen to be (0,0), but it actually doesn't matter where you choose to begin. In generating these images the point that you start with is moved around so many times that the importance of that first position is, in the end, thouroughly eroded. Like the classic street magic trick where you have to follow the ball underneath the three cups, after a while it seems impossible to determine where it all began anyway. NOTE: although the starting position may appear to be different for each choice of fractal, actually the red point is always (0,0). What's going on is that in each case we are looking at a different section of the cartesian plane.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 0, {style: 'blobs', blobsSize: 3}),
    },
    { // II
      title:
      &quot;II. The very first iteration&quot;,
      description:
      &quot;&lt;i&gt;This&lt;/i&gt; is the core process. We take the position of the last point we plotted (in this case the only point) and we use one of the rules to decide where to move it to. Here the last point (the starting point) has been marked in red, and the new point is marked in black. NOTE: you may have not noticed any change between this slide and the last slide. If that is the case it is because the transformation that was applied mapped the initial position right back onto itself. &lt;b&gt;If you re-run the process&lt;/b&gt; (you can do this by clicking again on the preset you wish to load, or clicking on the canvas itself) you will see that the new position is not the same every time - a different one of the transformation rules is chosen at random each time.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 1, {style: 'lines', blobsSize: 3}),
    },
    { // III
      title:
      &quot;III. More iterations, colorised&quot;,
      description:
      &quot;We make one small change to our method while things are still simple and uncluttered: we colour the lines and the points differently according to which transformation rule was responsible for each motion. The colours themselves are not significant, but lines with the same colour correspond to movements caused by the same transformation rule. This way it's a little easier to see what's happening under the hood.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 5, {style: 'lines', color: 'last', blobsSize: 3}),
      // function call:
      // IFS.get(eval(preset), 5, {style: 'lines', color: 'last'});
    },
    { // IV
      title:
      &quot;IV. 50 Steps in, some patterns emerge.&quot;,
      description:
      &quot;Here we plot the path that our first point follows as we apply this process over and over again, more and more times. Slowly, what seems chaotic shows form. From erratic motions to repeated patterns. Though the path is far from perfectly tracing the pattern we are seeking, we start to see its characteristics in the regions that are visited and revisited.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 50, {style: 'lines', color: 'last', blobsSize: 3}),
      // function call:
      // IFS.get(eval(preset), 10-1000, {style: 'lines', color: 'last'});
    },
    { // V
      title:
      &quot;V. The output after 2000 of these random jumps&quot;,
      description:
      &quot;This is perhaps my favourite step in the process. It is absolutely clear now that these rules when applied together produce something orderly, but the resulting form is still so messy and confusing. The step that nicely straddles the unpredictable beginnings and the completely predetermined end.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 2000, {style: 'lines', color: 'last', blobsSize: 0}),
      // function call:
      // IFS.get(eval(preset), 10,0000, {style: 'lines', color: 'last'});
    },
    { // VI
      title:
      &quot;VI. What you see when you remove all the connecting lines&quot;,
      description:
      &quot;The path becomes so tangled and self-crossing that it is easier to appreciate what's going on by actually giving up on following the movements and instead just focusing the spots which were visited along the way. Less ball of thread, more breadcrumbs. As we dot around, following one transformation after another, we place a marker at each resting place, colored according to the transformation responsible for its last motion. The result is much more sparse but much more orderly. The only thing left to do now is repeat the process many more times to flesh out the picture.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 2000, {color: 'last'}),
    },
    { // VII
      title:
      &quot;VII. Cranking up the iterations from 2,000 to 100,000&quot;,
      description:
      &quot;And suddenly the shape comes into focus, and refreshing the picture seems to have little effect other than to cause the dancing of points around their already well settled places. It turns out these positions were in some way inevitable.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 100000, {color: 'last'}),
    },
    { // VIII
      title:
      &quot;VIII. Superimposing the bounding boxes to indicate the different rules&quot;,
      description:
      &quot;Here we make one last addition to our visual exposition; one box surrounding the entire input region, and then one coloured output box for each rule making up the fractal definition. In this way the impact of each transformation is made absolutely apparent.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 100000, {color: 'last', bboxes: true}),
    },
    { // IX
      title:
      &quot;IX. Ending where we started&quot;,
      description:
      &quot;By removing the didactic coloring and inclusion of bounding boxes to indicate the transformations at work, we find ourselves back where we started - the process of generating the fractal from its transformation-specification is complete.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 250000, {color: 'uniform'}),
    },
  ];
&lt;/script&gt;

&lt;!-- interaction handling --&gt;
&lt;script&gt;
  // functions
  // events / content
  let slideNum = 0;
  let preset = 'binaryTree';
  let presets = [...document.getElementById('presets').childNodes];
  let loadPreset = (e) =&gt; {
    preset = e.target.alt;
    getFrame(frames[slideNum]);
  }
  for (index in presets) {
    if(presets[index].nodeName == 'INPUT') {
      presets[index].onclick = (e) =&gt; {
        for(indexB in presets) {
            presets[indexB].style = &quot;background-color: #ddd; font-weight: lighter;&quot;
        }
        e.target.style = &quot;background-color: #ddd; font-weight: heavier;&quot;
        preset = e.target.alt;
        getFrame(frames[slideNum]);
      };
    }
  }
  let frameDescriptionContainer = document.getElementsByName('frame-description-container');
  let nextButton = document.getElementById('next-button');
  let prevButton = document.getElementById('previous-button');
  let frameDescription = document.getElementById('frame-description');
  let frameTitle = document.getElementById('frame-title');
  let frameCanvas;
  let frameContext;
  let slideControls = document.getElementById('slide-controls');
  let canvasContainer = document.getElementById('canvas-container');
  let options = 
  nextButton.onclick = () =&gt; { 
    slideNum = (slideNum + 1 + 10) % 10;
    getFrame(frames[slideNum]);
  };
  prevButton.onclick = () =&gt; { 
    slideNum = (slideNum - 1 + 10) % 10;
    getFrame(frames[slideNum]);
  };
  const getFrame = (frame) =&gt; {
    if (canvasContainer.hidden == true) {
      canvasContainer.hidden = false;
      frameCanvas = document.createElement('canvas');
      canvasContainer.appendChild(frameCanvas);
      let containerWidth = canvasContainer.offsetWidth;
      frameCanvas.style = &quot;margin-right:auto; margin-left:auto; display:block;&quot;
      frameCanvas.width = containerWidth;
      frameCanvas.height = containerWidth;
      frameCanvas.id = &quot;frame-canvas&quot;
      frameCanvas.onclick = () =&gt; paint(frameCanvas, frames[slideNum].imageData());
    }
    slideControls.hidden = false;
    frameTitle.innerHTML = frame.title;
    frameDescription.innerHTML = frame.description;
    if (preset == &quot;random&quot; || preset == &quot;mapleLeaf&quot;) {
      IFS.defaultOptions.scale = 0.7;
    } else if (preset == &quot;binaryTree&quot;) {
      IFS.defaultOptions.scale = 0.8;
    } else {
      IFS.defaultOptions.scale = 0.9;
    }
    paint(frameCanvas, frame.imageData());
  }
  const download = () =&gt; {
    
  }
&lt;/script&gt;

&lt;p&gt;So there you have it, for some reason if you just choose any random starting point then plot the result of (also randomly) applying each transformation rule to that point over and over again, the result is a shockingly accurate approximation of your image.&lt;/p&gt;

&lt;h3 id=&quot;notes--clarifications&quot;&gt;Notes / Clarifications:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;This process is often referred to as the ‘chaos game’ method.&lt;/li&gt;
  &lt;li&gt;When I say that the transformations are chosen at random, that is true, and the probability of any particular transformation being chosen at a given iteration is something you have to specify before beginning the process. (Tweaking these probabilities has the effect of making regions in the output associated with the corresponding transformation either more or less dense with points ending up there)&lt;/li&gt;
  &lt;li&gt;About &lt;a href=&quot;https://github.com/joelstrouts/blog/blob/master/_includes/scripts/custom/IFS.js&quot;&gt;my implementation&lt;/a&gt;: It’s not very fast, at least at the time of writing. The methods I used to implement this IFS plotter gave no real consideration to computational efficiency. My priority was to model in the code my understanding of the problem as cleanly as possible in a familiar language. At some point in the future I may rewrite the performance critical parts, as it stands however, plotting &amp;gt;500,000 points at a time is quite resource intensive.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-does-it-work&quot;&gt;Why does it work?&lt;/h3&gt;
&lt;p&gt;I think what this really instills in me is the sense that there is something very robust about this ‘attractor’ property of the set. You really don’t have to try too hard to find it. I think this method of imaging the set is like taking a crayon imprint of a leaf through paper or something. A scattering of points over the relevant region can hardly &lt;em&gt;not&lt;/em&gt; find it because its ridges and valleys are just so prominent. The mathematics that grantees this sort of long term probabilistic certainty happens to belong to a branch called ‘ergodic theory’. That is the mathematics of long term behaviour of dynamical systems defined on probability measures.&lt;/p&gt;

&lt;p&gt;Probability measures? Yes one detail I did not mention above is that a more nuanced way of imaging the attractor, akin to the other formal definition given, comes from considering not input regions, but something more like input distributions. Probability measures, in fact. Then rather than just morphing one region into another, you flow one distribution into the next, where regions have a higher value according to the measure if you expect more points to map to that region after the transformations are applied. It allows you to go from a set with hard boundaries in black and white to a grey-scale reproduction with light and dark regions showing you where the transformations collect more or less of the points. It turns out that the picture you get with this dynamical approach is really a crayon imprint of the invariant probability measure, not the harsh black-and-white in-or-out set invariant.&lt;/p&gt;

&lt;h2 id=&quot;what-now&quot;&gt;What now?&lt;/h2&gt;

&lt;p&gt;Writing this program was frustrating at first but then I got quite into it! So it is very tempting to just keep improving on it, and I have a list of changes I’d like to make to it that could certainly keep me busy for the rest of my time here. I can’t do that though. This part is done. I haven’t reverse engineered anything! So now I’m dragging myself away from this part of the project. My next step is to try to reproduce part of the inverse procedure outlined in the 1994 paper “&lt;em&gt;Inverse and Approximation Problem for Two-Dimensional Fractal Sets&lt;/em&gt;”. I hope to have implemented the very first part of their method (application of a wavelet transform to identify periodic oscillations around regression line corresponding to the scaling factor of transformation rules) by… Wednesday? I think that’s optimistic. It’s kind of damning that all this work likely won’t even get me up to date with the 2000’s progress on the problem but that’s how it goes, I know. I’m learning lots.&lt;/p&gt;</content><author><name>Joel Strouts</name></author><summary type="html">I am about half way through my time working here and I have reached a crucial turning point in my research. All this time the goal has been to make progress on the reverse engineering problem, but it was first necessary to familiarise myself with the forward-engineering. I am now familiar with that forward-engineering. In this post I sum up what I’ve learned and embellish the descriptions with pretty outputs from the program I wrote. Note: if you’re not drawn in by technical details, don’t go! Skip to the interactive demonstration I’m very proud of it! Maybe the details will be more interesting after some intriguing pictures. There’s this one detail about the creation of these fractal images that really confused me to begin with (and still to an extent now, although familiarity softens much frustration), and that’s what I’d like to talk about here. It’s this mismatch between the theory as I understood it, and the actual methods used in practice which didn’t seem at all related to that theory. Here’s how I originally understood the process used to generate reproductions of fractal images: these fractals have smaller copies of themselves embedded within themselves if you specified the exact way that the copies were embedded, then you could reproduce the image by repeatedly making copies according to that rule For example: if you started with the stem of the fern, then copying it around over and over again, making smaller and smaller copies of that one stem, you would end up with a skeletal model of the same fern that - after enough iterations - would look just like the original. My reading on the topic of IFS fractals has informed me that this conception is not quite in line with the common formal definition. This is the gist of the mathematical formulation: Rules for how to make copies define a ‘contraction’ on the input space. (this is the formal way of saying the copies must be smaler than the original region, which makes intuitive sense because if that was not the case the process would grow outwards endlessly rather than settling down inwardly) the visual form we call the ‘fractal’ corresponds to the set of all points that are invariant under this contraction. ie. After applying all the rules, if the resulting set of points is identical to the set you started with then that set was invariant under the contraction, so you have identified the fractal set, called the attractor. this set of points is called the ‘attractor’ because no matter the region you start with, the application of the contraction rule always reduces the difference between the input region and the fractal set (an observation which can formalised by defining a distance function on the set of all compact regions in the space; the Hausdorf distance). It is therefore possible to generate an image of the attractor by choosing some reasonable starting set then repeatedly applying the contraction to that region until its form has mangled into one that ceases to change significantly on further contractive iterations. Now that is all well and good, but here’s the screwy thing: the method for generating these images is nothing like either of those descriptions. Nothing like it. I’m going to describe the actual method which is used in detail so hopefully you can understand how strange it is. Making the rules The idea of ‘contractions’ on the input space is a powerful one because it is not very prescriptive about the sorts of functions we have to use as transformation rules. It just enforces this intuitively reasonable notion that the repeated application of the rule has to result in a settling down not a blowing up. We will not work with this very general notion however, we are going to focus on one specific type of transformation which is particularly well suited to characterising fractal images as we are familiar with them: Affine transformations. Let’s define that term. A transformation is a rule that tells us how to move around different points based on their position. Once we know how to move individual points around we can then ask what happens to every point within a shape or region to see how it warps space at a more macro level. A rule that says ‘all points move to the position $(4,3)$’ is a perfectly good example of a transformation. A rule that says ‘multiply the $x$ coordinate by two’ is also a perfectly good transformation. They can be as simple or as complex as you like, so long as the definition is unambiguous for every input position. Transformation that completely mangles any input region into something unrecognisable will not be much use for describing fractal self similarity. We choose affine transformations to work with then because, like the name implies, while they may warp their input regions, the resulting outputs always share an affinity with the corresponding inputs. Each affine transformation can be uniquely specified by the way it morphs a rectangle in the input space to a parallelogram of some description in the output space, so you can think of affine transformations as encompassing all of: shifting, scaling (not necessarily by the same amount in each direction), and rotating. Mathematically speaking, they are given by the composition of a linear transformation and a translation: Where the light green matrix is the linear part of the composition, and the orange vector is the translation vector. The translation does nothing more than move the region from one location to another, whereas the linear transformation captures all of the squishing and rotating. Using the Rules That’s the bit which every conception of these IFS fractals agrees on. Affine transformations characterise the fractal. So you’ve settled on your copying rules, how do you draw a picture with them? The formal method outlined above says start with some other region then just keep morphing it with your rules over and over until it looks right. Pleasantly clean in its conception but somewhat of a pain computationally, to have to apply the function for every single point in some region. Here’s what’s actually done: The Image generation process, presented interactively and step by step: ↑ Select one of the above predefined rule sets to apply procedure to ↑ So there you have it, for some reason if you just choose any random starting point then plot the result of (also randomly) applying each transformation rule to that point over and over again, the result is a shockingly accurate approximation of your image. Notes / Clarifications: This process is often referred to as the ‘chaos game’ method. When I say that the transformations are chosen at random, that is true, and the probability of any particular transformation being chosen at a given iteration is something you have to specify before beginning the process. (Tweaking these probabilities has the effect of making regions in the output associated with the corresponding transformation either more or less dense with points ending up there) About my implementation: It’s not very fast, at least at the time of writing. The methods I used to implement this IFS plotter gave no real consideration to computational efficiency. My priority was to model in the code my understanding of the problem as cleanly as possible in a familiar language. At some point in the future I may rewrite the performance critical parts, as it stands however, plotting &amp;gt;500,000 points at a time is quite resource intensive. Why does it work? I think what this really instills in me is the sense that there is something very robust about this ‘attractor’ property of the set. You really don’t have to try too hard to find it. I think this method of imaging the set is like taking a crayon imprint of a leaf through paper or something. A scattering of points over the relevant region can hardly not find it because its ridges and valleys are just so prominent. The mathematics that grantees this sort of long term probabilistic certainty happens to belong to a branch called ‘ergodic theory’. That is the mathematics of long term behaviour of dynamical systems defined on probability measures. Probability measures? Yes one detail I did not mention above is that a more nuanced way of imaging the attractor, akin to the other formal definition given, comes from considering not input regions, but something more like input distributions. Probability measures, in fact. Then rather than just morphing one region into another, you flow one distribution into the next, where regions have a higher value according to the measure if you expect more points to map to that region after the transformations are applied. It allows you to go from a set with hard boundaries in black and white to a grey-scale reproduction with light and dark regions showing you where the transformations collect more or less of the points. It turns out that the picture you get with this dynamical approach is really a crayon imprint of the invariant probability measure, not the harsh black-and-white in-or-out set invariant. What now? Writing this program was frustrating at first but then I got quite into it! So it is very tempting to just keep improving on it, and I have a list of changes I’d like to make to it that could certainly keep me busy for the rest of my time here. I can’t do that though. This part is done. I haven’t reverse engineered anything! So now I’m dragging myself away from this part of the project. My next step is to try to reproduce part of the inverse procedure outlined in the 1994 paper “Inverse and Approximation Problem for Two-Dimensional Fractal Sets”. I hope to have implemented the very first part of their method (application of a wavelet transform to identify periodic oscillations around regression line corresponding to the scaling factor of transformation rules) by… Wednesday? I think that’s optimistic. It’s kind of damning that all this work likely won’t even get me up to date with the 2000’s progress on the problem but that’s how it goes, I know. I’m learning lots.</summary></entry><entry><title type="html">In McDonalds Again</title><link href="https://joelstrouts.com/2019/07/20/In-McDonalds-Again.html" rel="alternate" type="text/html" title="In McDonalds Again" /><published>2019-07-20T00:00:00+08:00</published><updated>2019-07-20T00:00:00+08:00</updated><id>https://joelstrouts.com/2019/07/20/In-McDonalds-Again</id><content type="html" xml:base="https://joelstrouts.com/2019/07/20/In-McDonalds-Again.html">&lt;p&gt;A brief update. An important work milestone and a vignette of how I spend my wild late nights in this vibrant, restless city - at McDonalds working.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h1 id=&quot;a-carafe-out-of-place&quot;&gt;A Carafe out of place&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=nI6nfACLPKQ&quot;&gt;(song to accompany this post)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My plan read “&lt;em&gt;write next blog by saturday&lt;/em&gt;”.&lt;/p&gt;

&lt;p&gt;Well it’s 4AM on Sunday morning (which, yes does still count as Saturday) and I’m at the 24 hour McDonald’s by the uni, celebrating - because I am now ready to &lt;strong&gt;begin&lt;/strong&gt; writing it.&lt;/p&gt;

&lt;p&gt;Fight club, the film (although I hear the book is pretty good, maybe better), has been on my mind. Good film. Specifically, right at the start where we are being introduced to the character of Edward Norton, and he tells us about his perfect, modern apartment - his obsession with Ikea, the hand crafted bowls and identity-defining dining set - then it all gets blown up. It’s become a big reference for me. Ed’s condo gets blown to pieces and even though he loved it so, in the end he’s thankful. He thought that he had been making his life more and more perfect but, in the void after the fire, he realised this: Rather than improving his life, he had become the possession of his possessions. By curating a life so exact in its comforts, by assigning such importance to every detail - every coffee cup, coaster, carafe - he suffered from an acute interior-design-related anxiety. An anxiety that he alone was responsible for creating, but nevertheless held him captive. To be unable to buy a new toothbrush because the handle must be rosewood (so as to match the cabinet doors) - Or: to be incapable of sleeping at a friend’s because their bedsheets have not the sufficient thread count. That’s the prison Norton had constructed for himself. And I think the film makes quite a persuasive argument, in this way, that possessions are not all that good. Edward Norton’s case is extreme, but the message is clear, caring about this stuff is a bit silly, and really caring about it might drive you so mad that you get insomnia and, one day, find that your home has spontaneously combusted.&lt;/p&gt;

&lt;p&gt;So Edward realises the error of his ways and begins beating up other men in pub basements. Hang on a minute, what was the moral of the story supposed to be again?&lt;/p&gt;

&lt;p&gt;Anyway, the reason it’s been a big reference for me - this conflict between curated comfort, and the liberty of holding nothing dear - is because I am Edward Norton before his apartment blows up. I have made my life very comfortable, in my very particular ways. I am always making it &lt;em&gt;more&lt;/em&gt; comfortable, and that suits me just fine most the time, until I remember that blazing fire, and Edward’s change of heart. Do I need a change of heart?&lt;/p&gt;

&lt;p&gt;I’ve never been able to stick to a routine, but I sure have built up a nice collection of &lt;em&gt;routines&lt;/em&gt;, and I like to carry them out just-so. Like here, now, at McDonald’s. I’ve only been in Hong Kong a little over two weeks (gee, that’s actually a while isn’t it?) but my order, the bubble tea and the 6 nuggets and fries, I think this is the fourth time I’ve got it. I will get it again, and in the exact same way. Same dips, same shaking spice. I will wear my favourite GAP hoodie (because the AC is a little too cold), I will put my phone in the inwards facing pocket of my Marimekko bum-bag. I will plug my chunky, curly corded headphones in and choose a playlist to listen to (or maybe just put my loves on shuffle). I know what does and does not go in every pocket. I could tell you now exactly what my pockets will contain a week from now. And when I finally get a stain on this jumper that won’t come out, or wear a hole in this bum bag, drop my phone, or God forbid, McDonald’s stops offering this promotion, I will find that really tough.&lt;/p&gt;

&lt;p&gt;The one area of my life I am most guilty of this anxiety-inducing dogged pursuit of, well - I don’t know what it’s even a pursuit of really. Marginal gains? That area is digital, electronic. When I proudly showed my research supervisor one of the little hacks I had put together, &lt;em&gt;he&lt;/em&gt; - post doctorate computer science researcher - called me a nerd. Perhaps efficiency hacks can be justified up to a point, but that seemed like an indication that perhaps the point is behind me.&lt;/p&gt;

&lt;p&gt;I am willing to endure so much frustration in the name of reducing frustration. This week has been a frustration filled one, and now - at it’s end - I have reached the bit with the gains and it’s pretty nice, Check it out!&lt;/p&gt;

&lt;h2 id=&quot;the-goods&quot;&gt;The Goods&lt;/h2&gt;
&lt;canvas id=&quot;my-canvas&quot; height=&quot;700&quot; width=&quot;600&quot; hidden=&quot;true&quot;&gt;&lt;/canvas&gt;
&lt;p&gt;&lt;input id=&quot;my-button&quot; type=&quot;button&quot; value=&quot;click here to generate a fern!&quot; /&gt;&lt;/p&gt;

&lt;script&gt;
  let canvas = document.getElementById('my-canvas');
  let button = document.getElementById('my-button');
  button.onclick = () =&gt; {
    canvas.hidden = false;
    paint(canvas, IFS.get(barnsleyFern, 250000, {colors: [[255,0,0]]}));
  }
 &lt;/script&gt;

&lt;p&gt;Assuming it worked, and there’s a box above this paragraph that a fern is drawn in when you press the submit button - I am pretty chuffed. The reason I’m questioning whether I’ve used my time well is because the ‘real’ work in producing that image was (to describe what I’ve done in the least favourable way) just me copying someone else’s code. What took the rest of the time, (or actually, most of the time) was all of the secondary stuff - the behind the scenes organisational stuff. I wanted it all &lt;em&gt;just so&lt;/em&gt;. Does the plumbing really need to be gilded? Well I’ve absolutely gilded this plumbing and, at the end of the day, I’m chuffed with the result. I had to rearrange all the bookshelves, move the bed to the other side of the room, replace all chevrons with stippling, but this; my little website setup - I can sleep soundly one more night with it like this.&lt;/p&gt;

&lt;h2 id=&quot;end&quot;&gt;End&lt;/h2&gt;

&lt;p&gt;And that’s where I’m going to leave it. A little thought about fight club, and a little research milestone. I’ll write about the maths behind it all, the programming, the life in Hong Kong - the books I’m reading, music I’m listening to, friends I’ve made, realisations I’ve had - I’ll write about them soon, next, later. Not in that order.&lt;/p&gt;</content><author><name>Joel Strouts</name></author><summary type="html">A brief update. An important work milestone and a vignette of how I spend my wild late nights in this vibrant, restless city - at McDonalds working.</summary></entry><entry><title type="html">Working in Hong Kong (Part 2)</title><link href="https://joelstrouts.com/2019/07/10/Working-in-Hong-Kong-Part-2.html" rel="alternate" type="text/html" title="Working in Hong Kong (Part 2)" /><published>2019-07-10T00:00:00+08:00</published><updated>2019-07-10T00:00:00+08:00</updated><id>https://joelstrouts.com/2019/07/10/Working-in-Hong-Kong-Part-2</id><content type="html" xml:base="https://joelstrouts.com/2019/07/10/Working-in-Hong-Kong-Part-2.html">&lt;h1 id=&quot;changing-tack&quot;&gt;Changing Tack&lt;/h1&gt;

&lt;p class=&quot;info&quot;&gt;&lt;img src=&quot;/images/beating-windwards.png&quot; alt=&quot;Beating to Windward&quot; /&gt;
Sailing is the art of manoeuvring a vessel to exploit the power of the wind. It is somewhat surprising, and entirely lovely, that this is still possible even when your destination demands that you head directly into the oncoming wind. The wind can be tamed even when it insists on pushing you backwards. Tacking is the name for the type of turn you must perform in order defy the wind’s wishes.&lt;/p&gt;

&lt;p&gt;In this post I describe the work I’m doing while I’m here. &lt;a href=&quot;joelstrouts.com/2019/07/08/Working-in-Hong-Kong-Part-1.html&quot;&gt;The last one&lt;/a&gt; explained how I got here and, in doing so, described the project I proposed in order to secure the opportunity. If I was working on that same project, an entire additional post to explain what I’m up to would be a bit redundant, so naturally - that’s not actually what I’m doing.&lt;/p&gt;

&lt;h2 id=&quot;my-options&quot;&gt;My Options&lt;/h2&gt;

&lt;p&gt;Here’s what happened: First contact with Professor Wang resulted in us scheduling a skype call to talk about the idea of working together - I was supposed to explain my project and describe the expectations I had of the experience. I was quite nervous, but I happily obliged and after ten minutes or so of discussion Professor Wang graciously informed me that my idea was fun, but not of real research interest, then without skipping a beat began to discuss a different problem he had been contemplating. I was blindsided! But the new problem we were discussing was very interesting. Let me try to explain it.&lt;/p&gt;

&lt;p&gt;The problem was to do with fractals. The exact definition of a fractal is a bit fussier than the common usage definition (it is more about a sort of scale-independent roughness). In this article we apply the more common definition: A structure is said to be fractal if it exhibits the property of self similarity.&lt;/p&gt;

&lt;h3 id=&quot;a-brief-discussion-of-fractals&quot;&gt;A Brief Discussion of Fractals&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/barnsley-fern.png&quot; alt=&quot;Barnsley Fern&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pictured above is one of the most well known fractals; the Barnsley Fern. Each individual frond looks like a smaller version of the whole thing, this is what we call self similar. Fractals can be dizzyingly complex, but because they follow a pattern, can be described in surprisingly compact ways. Compact representation, complex realisation. That’s a desirable combination. If you were dealing with a very complex, incredibly detailed problem, and you realised that actually there was an underlying fractal pattern to it, you would be liberated from worrying about all the fine details. Then you could just reason about the general pattern, since the behaviour would be the same at every level.&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Two examples:&lt;/strong&gt; I learned yesterday that some image compression algorithms work by identifying areas which can be described by fractals, because doing so simplifies the representation so much. Also, many games use fractal rules to generate elements of the environment, like mountain ranges, foliage etc. for the same reason.&lt;/p&gt;

&lt;p&gt;The fern pictured above can be generated by the repeated application of these rules:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\bbox[20px, border: 2px solid orange]{
\begin{align}
f_{1}(x,y)=\begin{bmatrix}0.00 &amp; 0.00\\0.00 &amp; 0.16\end{bmatrix}\phantom{-}&amp;\begin{bmatrix}x\\y\end{bmatrix} \\
f_{2}(x,y)=\begin{bmatrix}0.85 &amp; 0.04\\-0.04 &amp; 0.85\end{bmatrix}&amp;\begin{bmatrix}x\\y\end{bmatrix} + \begin{bmatrix}0,00\\1.60\end{bmatrix} \\
f_{3}(x,y)=\begin{bmatrix}0.00 &amp; 0.00\\0.00 &amp; 0.16\end{bmatrix}\phantom{-}&amp;\begin{bmatrix}x\\y\end{bmatrix} + \begin{bmatrix}0,00\\1.60\end{bmatrix} \\
f_{4}(x,y)=\begin{bmatrix}0.00 &amp; 0.00\\0.00 &amp; 0.16\end{bmatrix}\phantom{-}&amp;\begin{bmatrix}x\\y\end{bmatrix} + \begin{bmatrix}0,00\\0.44\end{bmatrix}
\end{align}
} %]]&gt;&lt;/script&gt;

&lt;p&gt;Where each function is what we call an &lt;a href=&quot;https://www.wikipedia.org/wiki/Affine_transformation&quot;&gt;&lt;em&gt;affine transformation&lt;/em&gt;&lt;/a&gt;, meaning they can be described by a combination of a linear transformation and a translation. Affine transformations let you shift and stretch your input in many ways, only dissalowing changes which would cause straight lines to become curved.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/fern-affines.png&quot; alt=&quot;Affine transformations generating the barnsley fern&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can see visually what those four affine transformations (that were provided in mathematical notation) really describe. Varying the coefficients that define these transformation can produce other fern like outputs and other forms, sometimes natural - often more abstract, too. A gallery of images produced in this way can be found &lt;a href=&quot;http://paulbourke.net/fractals/ifs/&quot;&gt;here&lt;/a&gt;. One such example is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/sand-dollar-IFS.jpg&quot; alt=&quot;Sand Dollar Fractal&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-suggestion&quot;&gt;The Suggestion&lt;/h3&gt;

&lt;p&gt;The problem was this: Rather than choosing affine transformations then seeing what image results, is it possible to reverse engineer what the transformations must have been just from the resulting image?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
  subgraph Not the problem
    a1[Function Defintions]--&amp;gt;a2[Picture of Fractal]
  end
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph RL
  subgraph The problem
    b2[Picture of Fractal]--&amp;gt;b1[Function Defintions]
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More specifically the question was: can you write a program that would automate this process? Write a program capable of reproducing input images with great accuracy when they contain fractal patterns.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
  subgraph What a solution would look like
    A[Input Image]--&amp;gt;B[Computer program]
    B--&amp;gt;C[Reproduction of input image]
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was pretty much the suggestion. I was not downtrodden that the Professor had expressed his disinterest in working on my original suggestion because he criticisms were reasonable (It is more of an exercise in pedagogy and design than a mathematics/ computer science research) and because I was flattered that despite this he was still interested in working with me and immediately suggested an interesting project that was accessible and relevant to me.&lt;/p&gt;

&lt;h3 id=&quot;the-dilemma--the-conclusion&quot;&gt;The Dilemma / The Conclusion&lt;/h3&gt;

&lt;p&gt;What about my original project? I secured my place on the scholarship program, at least superficially, for the express purpose of realising that idea. So although the prospect on working with Professor Wang at HKU was very exciting, it was not clear that it was the best thing to do. I asked Professor Wang if it would be possible to compromise and instead divide the time available evenly between work on my own project and on the problem he suggested. He responded that this was in theory possible but not optimal because he would not be able to contribute as much to my project so my being there would be of less use. Very understandable objection! I talked to the scholarship team in York and in the end we decided it was best to take the original offer. The scholarship is actually more about personal development than specific project outcomes. The opportunities to learn and grow as a person by taking this chance far outweighed what was offered by my other options. It still feels a bit wrong to have abandoned my project like that though, so, I have not shelved it completely. I’d like to frame what’s happening as more of a beating to windward sort of situation - and in the end my project will be the better for it.&lt;/p&gt;

&lt;h2 id=&quot;the-plan&quot;&gt;The Plan&lt;/h2&gt;

&lt;p&gt;So, that is why I am here and that is what I will be working on. Although  is not absolutely required that &lt;strong&gt;this&lt;/strong&gt; is the problem we work the whole time; perhaps if we reach a dead end, find something more interesting, or perhaps even solve the problem to our satisfaction, then we will work on something else. Nevertheless, right now the plan is just to tackle this problem with maximum vitality and then reassess the situation as necessary.&lt;/p&gt;

&lt;h3 id=&quot;conceptual-level&quot;&gt;Conceptual level&lt;/h3&gt;

&lt;p&gt;So, my first thought on seeing the problem was that it was really composed of two separate sub-problems. First, ‘&lt;em&gt;feature extraction&lt;/em&gt;’. There is a natural sense that we have, as humans, upon seeing an image - ‘oh it has this pattern’ or, ‘oh, it has that pattern’. When we see a picture of the fern we are immediately aware that the form has structure, and if asked we could describe that structure ‘this frond is like that frond, this stem like the other’.  We have an intuition about it. This is not so obvious to a computer. Let’s say you have identified which parts look like copies of larger parts though, what’s left to do is figure out how to encode that information as a set of transformations. This is what I saw:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
  A[Input image]--&amp;gt;b1[feature extraction]
  subgraph The program
    b1--&amp;gt;b2[transformation inference]
  end
  b2--&amp;gt;C[Reproduced input image]
  b1-.-d1(very difficult?)
  b2-.-d2(not so difficult?)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have talked to Professor Wang and he agrees that this is a natural way of dividing up the problem, and that it would be wise to begin with that second sub-problem. To begin with the feature identification process can be performed by the user of the program interactively.&lt;/p&gt;

&lt;h3 id=&quot;practical-level&quot;&gt;Practical Level&lt;/h3&gt;

&lt;p&gt;I have had a lot of problems choosing the wrong technology in the past. I think I’ve been too ambitious - trying to optimise for learning potential not just practicality, so choosing something slightly too unfamiliar or demanding, or perhaps with poor support. This time I will try to avoid making the same mistake. Practically, that means I will try:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Using javascript because I’m more familiar with it,&lt;/li&gt;
  &lt;li&gt;Using python because it’s well supported&lt;/li&gt;
  &lt;li&gt;Using libraries where possible so I don’t keep trying to re-invent the wheel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additionally, my focus right away will just to get something, anything, up and running as quickly as possible as I have often been guilty of analysis paralysis. Soon (by the start of next week?), I hope to be able to embed a barnsley fern that I have generated myself, ideally in an interactive format.&lt;/p&gt;

&lt;h2 id=&quot;obstacles&quot;&gt;Obstacles&lt;/h2&gt;

&lt;p&gt;Generally, thinking of the project as a whole, I see many obstacles. Especially in the second part. For now I’ll focus on the near term.&lt;/p&gt;

&lt;p&gt;My primary practical concern was, initially, technology. I had talked to the Professor about what technology he would use to implement a demo of a program like this and he suggested $\texttt{c++}$. I have never used $\texttt{c++}$ before so that did worry me a bit. Researching this approach showed me that it would likely involve learning about a graphics library like &lt;a href=&quot;https://en.m.wikipedia.org/wiki/OpenGL&quot;&gt;OpenGL&lt;/a&gt;, which in turn meant learning about graphics pipelines, with shaders and tesselaters, and rasterization. I still want to learn those things but I now see them as secondary to my real target, and perhaps even distractions if I focus on them.&lt;/p&gt;

&lt;p&gt;Other than that, I think that the applicability of this approach (entirely affine transformations based) concerns me somewhat. Yes, you can generate many fern like structures this way, even in three dimensions (resulting in a form like a &lt;a href=&quot;https://en.m.wikipedia.org/wiki/Romanesco_broccoli&quot;&gt;Romanesco cauliflower&lt;/a&gt; but these forms are almost &lt;em&gt;too&lt;/em&gt; regular, and I think do not really capture the full breadth of self similar structures.&lt;/p&gt;

&lt;p&gt;I must say though, once my short term goal was clear (write a simple program in any language which will generate Bernsley-Fern type fractals and allow you to vary the underlying affine transformations), I felt less bothered by the potential difficulties down the road. First, this - then that.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I need to get on with it! Tomorrow I begin.&lt;/p&gt;</content><author><name>Joel Strouts</name></author><summary type="html">Changing Tack Sailing is the art of manoeuvring a vessel to exploit the power of the wind. It is somewhat surprising, and entirely lovely, that this is still possible even when your destination demands that you head directly into the oncoming wind. The wind can be tamed even when it insists on pushing you backwards. Tacking is the name for the type of turn you must perform in order defy the wind’s wishes. In this post I describe the work I’m doing while I’m here. The last one explained how I got here and, in doing so, described the project I proposed in order to secure the opportunity. If I was working on that same project, an entire additional post to explain what I’m up to would be a bit redundant, so naturally - that’s not actually what I’m doing. My Options Here’s what happened: First contact with Professor Wang resulted in us scheduling a skype call to talk about the idea of working together - I was supposed to explain my project and describe the expectations I had of the experience. I was quite nervous, but I happily obliged and after ten minutes or so of discussion Professor Wang graciously informed me that my idea was fun, but not of real research interest, then without skipping a beat began to discuss a different problem he had been contemplating. I was blindsided! But the new problem we were discussing was very interesting. Let me try to explain it. The problem was to do with fractals. The exact definition of a fractal is a bit fussier than the common usage definition (it is more about a sort of scale-independent roughness). In this article we apply the more common definition: A structure is said to be fractal if it exhibits the property of self similarity. A Brief Discussion of Fractals Pictured above is one of the most well known fractals; the Barnsley Fern. Each individual frond looks like a smaller version of the whole thing, this is what we call self similar. Fractals can be dizzyingly complex, but because they follow a pattern, can be described in surprisingly compact ways. Compact representation, complex realisation. That’s a desirable combination. If you were dealing with a very complex, incredibly detailed problem, and you realised that actually there was an underlying fractal pattern to it, you would be liberated from worrying about all the fine details. Then you could just reason about the general pattern, since the behaviour would be the same at every level. Two examples: I learned yesterday that some image compression algorithms work by identifying areas which can be described by fractals, because doing so simplifies the representation so much. Also, many games use fractal rules to generate elements of the environment, like mountain ranges, foliage etc. for the same reason. The fern pictured above can be generated by the repeated application of these rules: Where each function is what we call an affine transformation, meaning they can be described by a combination of a linear transformation and a translation. Affine transformations let you shift and stretch your input in many ways, only dissalowing changes which would cause straight lines to become curved. Here you can see visually what those four affine transformations (that were provided in mathematical notation) really describe. Varying the coefficients that define these transformation can produce other fern like outputs and other forms, sometimes natural - often more abstract, too. A gallery of images produced in this way can be found here. One such example is shown below. The Suggestion The problem was this: Rather than choosing affine transformations then seeing what image results, is it possible to reverse engineer what the transformations must have been just from the resulting image? graph LR subgraph Not the problem a1[Function Defintions]--&amp;gt;a2[Picture of Fractal] end graph RL subgraph The problem b2[Picture of Fractal]--&amp;gt;b1[Function Defintions] end More specifically the question was: can you write a program that would automate this process? Write a program capable of reproducing input images with great accuracy when they contain fractal patterns. graph LR subgraph What a solution would look like A[Input Image]--&amp;gt;B[Computer program] B--&amp;gt;C[Reproduction of input image] end That was pretty much the suggestion. I was not downtrodden that the Professor had expressed his disinterest in working on my original suggestion because he criticisms were reasonable (It is more of an exercise in pedagogy and design than a mathematics/ computer science research) and because I was flattered that despite this he was still interested in working with me and immediately suggested an interesting project that was accessible and relevant to me. The Dilemma / The Conclusion What about my original project? I secured my place on the scholarship program, at least superficially, for the express purpose of realising that idea. So although the prospect on working with Professor Wang at HKU was very exciting, it was not clear that it was the best thing to do. I asked Professor Wang if it would be possible to compromise and instead divide the time available evenly between work on my own project and on the problem he suggested. He responded that this was in theory possible but not optimal because he would not be able to contribute as much to my project so my being there would be of less use. Very understandable objection! I talked to the scholarship team in York and in the end we decided it was best to take the original offer. The scholarship is actually more about personal development than specific project outcomes. The opportunities to learn and grow as a person by taking this chance far outweighed what was offered by my other options. It still feels a bit wrong to have abandoned my project like that though, so, I have not shelved it completely. I’d like to frame what’s happening as more of a beating to windward sort of situation - and in the end my project will be the better for it. The Plan So, that is why I am here and that is what I will be working on. Although is not absolutely required that this is the problem we work the whole time; perhaps if we reach a dead end, find something more interesting, or perhaps even solve the problem to our satisfaction, then we will work on something else. Nevertheless, right now the plan is just to tackle this problem with maximum vitality and then reassess the situation as necessary. Conceptual level So, my first thought on seeing the problem was that it was really composed of two separate sub-problems. First, ‘feature extraction’. There is a natural sense that we have, as humans, upon seeing an image - ‘oh it has this pattern’ or, ‘oh, it has that pattern’. When we see a picture of the fern we are immediately aware that the form has structure, and if asked we could describe that structure ‘this frond is like that frond, this stem like the other’. We have an intuition about it. This is not so obvious to a computer. Let’s say you have identified which parts look like copies of larger parts though, what’s left to do is figure out how to encode that information as a set of transformations. This is what I saw: graph LR A[Input image]--&amp;gt;b1[feature extraction] subgraph The program b1--&amp;gt;b2[transformation inference] end b2--&amp;gt;C[Reproduced input image] b1-.-d1(very difficult?) b2-.-d2(not so difficult?) I have talked to Professor Wang and he agrees that this is a natural way of dividing up the problem, and that it would be wise to begin with that second sub-problem. To begin with the feature identification process can be performed by the user of the program interactively. Practical Level I have had a lot of problems choosing the wrong technology in the past. I think I’ve been too ambitious - trying to optimise for learning potential not just practicality, so choosing something slightly too unfamiliar or demanding, or perhaps with poor support. This time I will try to avoid making the same mistake. Practically, that means I will try: Using javascript because I’m more familiar with it, Using python because it’s well supported Using libraries where possible so I don’t keep trying to re-invent the wheel Additionally, my focus right away will just to get something, anything, up and running as quickly as possible as I have often been guilty of analysis paralysis. Soon (by the start of next week?), I hope to be able to embed a barnsley fern that I have generated myself, ideally in an interactive format. Obstacles Generally, thinking of the project as a whole, I see many obstacles. Especially in the second part. For now I’ll focus on the near term. My primary practical concern was, initially, technology. I had talked to the Professor about what technology he would use to implement a demo of a program like this and he suggested $\texttt{c++}$. I have never used $\texttt{c++}$ before so that did worry me a bit. Researching this approach showed me that it would likely involve learning about a graphics library like OpenGL, which in turn meant learning about graphics pipelines, with shaders and tesselaters, and rasterization. I still want to learn those things but I now see them as secondary to my real target, and perhaps even distractions if I focus on them. Other than that, I think that the applicability of this approach (entirely affine transformations based) concerns me somewhat. Yes, you can generate many fern like structures this way, even in three dimensions (resulting in a form like a Romanesco cauliflower but these forms are almost too regular, and I think do not really capture the full breadth of self similar structures. I must say though, once my short term goal was clear (write a simple program in any language which will generate Bernsley-Fern type fractals and allow you to vary the underlying affine transformations), I felt less bothered by the potential difficulties down the road. First, this - then that. Conclusion I need to get on with it! Tomorrow I begin.</summary></entry><entry><title type="html">Working in Hong Kong (Part 1)</title><link href="https://joelstrouts.com/2019/07/08/Working-in-Hong-Kong-Part-1.html" rel="alternate" type="text/html" title="Working in Hong Kong (Part 1)" /><published>2019-07-08T00:00:00+08:00</published><updated>2019-07-08T00:00:00+08:00</updated><id>https://joelstrouts.com/2019/07/08/Working-in-Hong-Kong-Part-1</id><content type="html" xml:base="https://joelstrouts.com/2019/07/08/Working-in-Hong-Kong-Part-1.html">&lt;p&gt;For the next two months I am working in Hong Kong. While I’m here I think it would be helpful to document my time and the work I’m doing. So that those posts are not completely without context, I will take the next two posts to explain: First - Who I am and how I got here, and second - a proper exposition of the problem I will (at least initially) be working on while I’m here.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h1 id=&quot;who-am-i&quot;&gt;Who Am I?&lt;/h1&gt;

&lt;p&gt;I’m a maths student (just finished my second year) at &lt;a href=&quot;https://www.york.ac.uk&quot;&gt;York University&lt;/a&gt;. In my first year I was intent on lining up something interesting to do in the summer break, so I talked to my supervisor and he recommended looking into a programme called the Laidlaw scholarship. The purpose of the program was broadly to encourage undergraduate research. Open to all students with at least two years of their degree left before graduation. This was the deal:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Suggest a project of your own devising, complete with research plan and personal statement&lt;/li&gt;
  &lt;li&gt;If shortlisted then you would also be subjected to a logical reasoning test and interview process&lt;/li&gt;
  &lt;li&gt;Selected applicants would receive funding to complete whichever project they put forward in their application, and also be enrolled in a leadership development program.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I knew exactly what I would have &lt;em&gt;liked&lt;/em&gt; to work on as a scholarship beneficiary - but I didn’t fancy my chances getting it.&lt;/p&gt;

&lt;h2 id=&quot;laidlaw-the-dream-project&quot;&gt;Laidlaw: The Dream Project&lt;/h2&gt;

&lt;p&gt;There are two little projects I worked on long ago that I never dislodged from my mind and ended up becoming entangled with one another. The story of those two mini projects together tell the story of this bigger project I am now in the middle of. First: learning to code.&lt;/p&gt;

&lt;h3 id=&quot;division-problems&quot;&gt;Division problems&lt;/h3&gt;
&lt;p&gt;I was adamant (to the detriment of my actual exam grades at the time) - I &lt;em&gt;would&lt;/em&gt; learn to program. I had tried working through some courses on &lt;a href=&quot;https://codeacademy.com&quot;&gt;codeacademy&lt;/a&gt; but nothing really stuck, in the end what worked for me was playing around with making my own web-pages/websites&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. To would google ‘simple programming projects’ and complete anything I could. There was one project, simple remit, that really intrigued me. The task was simply to create a web page with two elements: an input box, and a submit button. When you typed a number into the box and hit submit, the idea was that the webpage would then display one of two different responses:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“Your number WAS a multiple of 6 :)”, or:&lt;/li&gt;
  &lt;li&gt;“Your number WAS NOT a multiple of 6 :(“&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sure, not particularly interesting, but good coding practice I thought. Once I got it working I didn’t move on right away but instead tried some variations on the core idea. First: Why six? It could have been any number, so I made the divisor a variable and played around with different values. Once It could handle any divisor I tried the idea of doing two divisibility checks at once - now the program showed two lines when you submitted your number: &lt;em&gt;Is your number a multiple of 6?&lt;/em&gt; AND &lt;em&gt;Is your number a multiple of 4?&lt;/em&gt;. It was still pretty boring. I tried instead not one, not two, but a bunch. At that point it became a bit more interesting.&lt;/p&gt;

&lt;p&gt;The output looked like a 20 item checklist. As you cycled through inputs, the lines of text would perform a little dance as the divisors flicked on and off. There was a pleasing sort of pattern to it, the second line oscillating on and off with every next number, the third similar but instead going: on, off, off, on, off off. All of them related but not quite in sync. You could gleam something deeper was going on, but still, all of this information was being displayed in such a quaint way: lines of text of different length either affirming divisibility or stating lack thereof. Surely, &lt;em&gt;surely&lt;/em&gt;, this should be represented graphically? Just literal check boxes would be superior to these verbose textual descriptions. The problem was: although I could picture in my mind what this far superior graphical replacement would look like, my programming abilities at the time were prohibitive of such an endeavour.&lt;/p&gt;

&lt;h4 id=&quot;enter-a-whole-number&quot;&gt;Enter a whole number&lt;/h4&gt;
&lt;script&gt;
  function check_for_submit(e) {
    if (e.keyCode == 13) {
      check_divisibility();
      return false;
    } else if (e.keyCode == 38) {
      increase_and_submit();
      return false;
    } else if (e.keyCode == 40) {
      decrease_and_submit();
      return false;
    } else {
      return true;
    }
  }
&lt;/script&gt;

&lt;p&gt;&lt;input id=&quot;division_number&quot; type=&quot;number&quot; onkeydown=&quot;return check_for_submit(event)&quot; onkeypress=&quot;return check_for_submit(event)&quot; /&gt;
&lt;input id=&quot;division_submit&quot; value=&quot;submit&quot; type=&quot;submit&quot; /&gt;
&lt;br /&gt;
&lt;input id=&quot;increase_button&quot; type=&quot;button&quot; value=&quot;increase&quot; /&gt;
&lt;input id=&quot;decrease_button&quot; type=&quot;button&quot; value=&quot;decrease&quot; /&gt;&lt;/p&gt;
&lt;div id=&quot;output_div&quot;&gt;&lt;/div&gt;

&lt;script&gt;
  let check_divisibility = function check_divisibility() {
    let number = document.getElementById(&quot;division_number&quot;).value;
    for (var i = 1; i &lt;= 20; i++) {
      var response_div = document.getElementById(&quot;response_&quot; + i);
      while (response_div.firstChild) {
          response_div.removeChild(response_div.firstChild);
      }
      if (number % i == 0) {
        response_div.appendChild(document.createTextNode(&quot;Your number WAS a multiple of &quot; + i + &quot; :)&quot;));
      } else {
        response_div.appendChild(document.createTextNode(&quot;Your number WAS NOT a multiple of &quot; + i + &quot; :(&quot;));
      }
    }
  }
  let increase_and_submit = function increase_and_submit() {
    let input = document.getElementById(&quot;division_number&quot;);
    input.value = Number.parseInt(input.value, 10) + 1;
    check_divisibility();
  }
  let decrease_and_submit = function decrease_and_submit() {
    let input = document.getElementById(&quot;division_number&quot;);
    input.value = Number.parseInt(input.value, 10) - 1;
    check_divisibility();
  }

  document.getElementById(&quot;division_submit&quot;).addEventListener(&quot;click&quot;, check_divisibility, false);
  document.getElementById(&quot;increase_button&quot;).addEventListener(&quot;click&quot;, increase_and_submit, false);
  document.getElementById(&quot;decrease_button&quot;).addEventListener(&quot;click&quot;, decrease_and_submit, false);

  for (var i = 1; i &lt;= 20; i++) {
    var response_div = document.createElement(&quot;div&quot;);
    response_div.setAttribute(&quot;id&quot;, &quot;response_&quot; + i);
    document.getElementById(&quot;output_div&quot;).appendChild(response_div);
  }

&lt;/script&gt;

&lt;h3 id=&quot;prime-factor-knitting&quot;&gt;Prime Factor Knitting&lt;/h3&gt;

&lt;p&gt;I’m not sure how I found myself there but at some time, now long distant, I came across &lt;a href=&quot;http://sonderbooks.com/blog/?p=843&quot;&gt;this&lt;/a&gt; page. The amateur book reviewer and mathematics enthusiast Sondra Eklund had knitted a jumper with an interesting pattern.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/pfsweater_front.jpg&quot; alt=&quot;Prime Factor Sweater&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The design featured a grid of colourful blocks on a white background. Truthfully, it looked like it could have been a homage to the &lt;a href=&quot;https://www.wikipedia.org/wiki/International_maritime_signal_flags&quot;&gt;international maritime signal flag alphabet&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/flag_alphabet.jpg&quot; alt=&quot;Signal Flag Alphabet Graphic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It was, in fact, a diagrammatic (knitted) presentation of the numbers 1-100 where the representation of each number depended on its &lt;a href=&quot;https://www.wikipedia.org/wiki/International_maritime_signal_flags&quot;&gt;prime factorization&lt;/a&gt;. The idea was simple:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Give each number its own square on the grid, then split that square into as many parts as it has prime factors.&lt;/li&gt;
  &lt;li&gt;Assign each prime number a different colour, then fill in each square’s subdivisions accordingly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;

&lt;p&gt;The prime divisors of $60$ are $2$, $2$, $3$, and $5$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
A(60)--&amp;gt;B(2)
A--&amp;gt;C(30)
C--&amp;gt;D(2)
C--&amp;gt;E(15)
E--&amp;gt;F(3)
E--&amp;gt;G(5)
classDef prime stroke-width:4px;
class B,D,F,G prime;
style B fill: #0a69ff
style D fill: #0a69ff
style F fill: #ff4b64
style G fill: #ffd26e
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If, then, we decided to assign the colours blue, red, and yellow to the primes $2$ $3$, and $5$ respectively (to match the choice Sondra made in her jumper) - the number 60 would be represented with four blocks like this:&lt;/p&gt;
&lt;div id=&quot;bars&quot;&gt;&lt;/div&gt;
&lt;script&gt;
  var input = [2,2,3,5];
  var anchor = document.getElementById(&quot;bars&quot;);
  // the variable `input` has been passed to
// this code chunk with include data.
// the variable `anchor` is a div where the include
// was called

function append_style(elem, addendum) {
  var style_string = elem.getAttribute('style');
  if (style_string == null) {
    elem.setAttribute('style', addendum);
  } else {
    elem.setAttribute('style', style_string + addendum);
  }
}

function style_setter(div, attribute, value) {
  append_style(div, attribute + ': ' + value + ';');
}

function div_maker(name) {
  var my_div = document.createElement('div');
  my_div.setAttribute('id', name);
  return my_div;
}

function anchor_appender(div) {
  anchor.appendChild(div);
}

function painter(div, color) {
  var color_string = 
    ' background-color: ' + color + ';' +
    'box-sizing: border-box;' +
    'border: 4px solid white;' +
    'float: left'
  append_style(div, color_string);
}

for (var factor of input) {
  var div = div_maker('factor_' + factor);
  style_setter(div, 'width', '2em');
  style_setter(div, 'height', '8em');
  if (factor == 2) {
    painter(div, '#282dff');
  } else if (factor == 3) {
    painter(div, '#cd0028');
  } else if (factor == 5) {
    painter(div, '#f0c364');
  }
  anchor_appender(div);
}

style_setter(anchor, 'width', '8em');
style_setter(anchor, 'height', '8em');

&lt;/script&gt;

&lt;p&gt;Or like this perhaps, depending on how you decide to arrange the blocks:&lt;/p&gt;
&lt;div id=&quot;blocks&quot;&gt;&lt;/div&gt;
&lt;script&gt;
  var input = [3,5,2,2];
  var anchor = document.getElementById(&quot;blocks&quot;);
  // the variable `input` has been passed to
// this code chunk with include data.
// the variable `anchor` is a div where the include
// was called

function append_style(elem, addendum) {
  var style_string = elem.getAttribute('style');
  if (style_string == null) {
    elem.setAttribute('style', addendum);
  } else {
    elem.setAttribute('style', style_string + addendum);
  }
}

function style_setter(div, attribute, value) {
  append_style(div, attribute + ': ' + value + ';');
}

function div_maker(name) {
  var my_div = document.createElement('div');
  my_div.setAttribute('id', name);
  return my_div;
}

function anchor_appender(div) {
  anchor.appendChild(div);
}

function painter(div, color) {
  var color_string = 
    ' background-color: ' + color + ';' +
    'box-sizing: border-box;' +
    'border: 4px solid white;' +
    'float: left'
  append_style(div, color_string);
}

for (var factor of input) {
  var div = div_maker('factor_' + factor);
  style_setter(div, 'width', '4em');
  style_setter(div, 'height', '4em');
  if (factor == 2) {
    painter(div, '#282dff');
  } else if (factor == 3) {
    painter(div, '#cd0028');
  } else if (factor == 5) {
    painter(div, '#f0c364');
  }
  anchor_appender(div);
}

style_setter(anchor, 'width', '8em');
style_setter(anchor, 'height', '8em');

&lt;/script&gt;

&lt;p&gt;and if you take another look at the jumper you can see that’s exactly what has been done:
&lt;img src=&quot;/images/pf_sweater_annotated.jpg&quot; alt=&quot;annotated jumper image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I loved the design, I loved the concept. I had never seen something like that before. Wouldn’t it be nice if there was a nice crisp digital version though? Something that would make a nice abstract looking poster I thought. Rather than a blurry picture of a jumper. I don’t think that really does the idea justice. Amazing jumper - not the ultimate, definite presentation of a very neat idea. I thought I’d make my own version…&lt;/p&gt;

&lt;h4 id=&quot;my-attempt&quot;&gt;My Attempt&lt;/h4&gt;

&lt;p&gt;Turns out it’s a lot of work! I can’t imagine how long it took to knit that jumper - bloody hell. I spent many many hours aligning rectangles of different widths and colors to eventually produce this image:
&lt;img src=&quot;/images/old_poster.jpg&quot; alt=&quot;old prime factor poster design&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And although I was vary very proud of it at the time, and quite convinced of my graphic designing abilities, after making many more iterations of the design I now look back on it with fond nostalgia and slight amusement. What stuck with me most about the experience was the tedium of the creation. It was so painfully clear that this was not a task best suited for human completion. It should be possible to draw this diagram with a computer program!&lt;/p&gt;

&lt;h2 id=&quot;the-scholarly-life&quot;&gt;The Scholarly Life&lt;/h2&gt;

&lt;p&gt;I made quite a few little projects relating to these prompts over the years. Trying to find a solution, experimenting with different approaches, finding commonalities. I learned slowly but I think I learned a lot. When the suggestion of applying to the Laidlaw scholarship was made to me, I had a fairly clear vision (or so I thought) of the ultimate, pedagogical, artistic, freely accessible, intuitive tool that I wanted to author to solve these two problems, and all the problems that lay in the space between them, and also many problems separate but related. I was enthused. I wanted to make art, and to teach, and inspire curiosity. It went down well, I got the scholarship.&lt;/p&gt;

&lt;p&gt;After my first summer of working on the problem, I had not authored such a solution. It turned out my vision was not so clear after all. I spent a lot of time diagramming the problem, and re-diagramming the problem. In some sense what I imagined was simple, it’s just that I lacked all of the understanding necessary to render it simple. I learned a lot that summer. Exiting the year without even half the tool I pictured stung though. After all my diagramming I did at least understand what I was trying to achieve in a technical sense, and that knowledge is summarised in this research poster I created to display at the Laidlaw conference we attended last year:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/research_poster.png&quot; alt=&quot;research poster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can see in the top right a more polished version of the graphic inspired by Sondra Ekland’s jumper, and along the bottom three images exploring different aspects of the type of divisibility visualisation I described before. In the middle of the poster is my attempt to to explain how my proposed program would go about creating these graphics in a general sense.&lt;/p&gt;

&lt;p&gt;The totality of impact and value that summer had cannot really be described, not in a poster or a blog post. I learned a lot, even if I didn’t make a shiny program.&lt;/p&gt;

&lt;p&gt;Regardless, it’s a two year program where a bit of failure (maybe even a lot!) is expected, understood, and appropriately provisioned for. All the better to prepare for the second year. So, the second year - what to do?&lt;/p&gt;

&lt;h2 id=&quot;the-second-year&quot;&gt;The Second Year&lt;/h2&gt;

&lt;p&gt;The Laidlaw programme runs internationally at a number of research institutions. There is drive to enable international research collaboration among institutions and scholars. I found the prospect of researching at a different university, and experiencing life elsewhere at the same time very appealing so I looked into my options. The project has been very much self defined and self driven so there was not a clear blueprint for collaboration. My approach was to first find people I wanted to work with by combing through the associated uni’s mathematics and computer science faculty for researchers with overlapping interests - then if they were willing to talk to me we would figure out the details as needed.&lt;/p&gt;

&lt;p&gt;Without any leads in particular to follow, first I reached out to &lt;a href=&quot;http://www.cs.toronto.edu/~david/index.html&quot;&gt;David Liu&lt;/a&gt; from Toronto university. Communication was like croquet, passing messages through the appropriate wickets of administration. I was fortunate to have the support of the scholarship to enable communication whatsoever. When a message weaved its way back to me the game was up - David was intrigued, but unfortunately not available to work together over the proposed time period.&lt;/p&gt;

&lt;p&gt;It didn’t seem wise to force the project to be collaborative if the proper impetus wasn’t there, so I was hesitant to contact just anybody. Fortunately, shortly after hearing the bad news about Toronto the Laidlaw team here at York caught word that Hong Kong university was particular keen to cross pollinate scholars in the future. With this new information, I again trawled the faculty pages and found a professor I must have missed first time round, because his research areas fit my project direction incredibly well. This time I was told I could contact the academic directly, so I composed an email to &lt;a href=&quot;http://www.cs.hku.hk/research/profile.jsp?teacher=wenping&quot;&gt;Professor Wenping Wang&lt;/a&gt; explaining my plans, attaching my research poster and copying in the relevant people - and I heard back the same evening! He was interested in collaborating.&lt;/p&gt;

&lt;p&gt;The plans we made (what I will be doing now I’m here) will be outlined in the second part of this blog!&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;It turns out the latter is much harder than the former. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Joel Strouts</name></author><summary type="html">For the next two months I am working in Hong Kong. While I’m here I think it would be helpful to document my time and the work I’m doing. So that those posts are not completely without context, I will take the next two posts to explain: First - Who I am and how I got here, and second - a proper exposition of the problem I will (at least initially) be working on while I’m here.</summary></entry><entry><title type="html">Scratch</title><link href="https://joelstrouts.com/2000/01/01/Scratch.html" rel="alternate" type="text/html" title="Scratch" /><published>2000-01-01T00:00:00+08:00</published><updated>2000-01-01T00:00:00+08:00</updated><id>https://joelstrouts.com/2000/01/01/Scratch</id><content type="html" xml:base="https://joelstrouts.com/2000/01/01/Scratch.html">&lt;!-- 
  TODO:
  - add final slide with interactive options for controlling
  all parameters
  - add feature to reveal report on previously loaded system of
  equations on hover
  - make resolution not depend on computed width, more pixels can suuurely fit on the screen damnit!
--&gt;
&lt;!-- contains the whole bit to be embedded in the page --&gt;
&lt;div style=&quot;background-color: #f5f5f5; padding: 20px; border-radius: 2.1rem; border: 1px solid #4141ff&quot;&gt;
  &lt;!-- contains the visualisations --&gt;
  &lt;div id=&quot;canvas-container&quot; hidden=&quot;true&quot; style=&quot;margin-bottom: 0.5rem&quot;&gt;
  &lt;/div&gt;
  &lt;!-- contains report on last generation --&gt;
  &lt;div id=&quot;report&quot;&gt;&lt;/div&gt;
  &lt;!-- contains the buttons --&gt;
  &lt;div id=&quot;presets&quot;&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Barnsley Fern&quot; alt=&quot;barnsleyFern&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Maple Leaf&quot; alt=&quot;mapleLeaf&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Binary Tree&quot; alt=&quot;binaryTree&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Serpinski&quot; alt=&quot;serpinski&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Sand Dollar&quot; alt=&quot;sandDollar&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;Random&quot; alt=&quot;random&quot; /&gt;
  &lt;/div&gt;
  &lt;!-- contains the textual desctiption --&gt;
  &lt;h4 id=&quot;frame-title&quot;&gt;↑ Select one of the above predefined rule sets to apply procedure to ↑&lt;/h4&gt;
  &lt;div id=&quot;slide-controls&quot; hidden=&quot;true&quot;&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;previous slide&quot; id=&quot;previous-button&quot; /&gt;
    &lt;input style=&quot;background-color: #ddd&quot; type=&quot;button&quot; value=&quot;next slide&quot; id=&quot;next-button&quot; /&gt;
  &lt;/div&gt;
  &lt;div id=&quot;frame-description-container&quot;&gt;
  &lt;p style=&quot;padding: 0.5rem 1rem; border-top: 1px solid #333333; font-size: 1.1em;&quot; id=&quot;frame-description&quot;&gt;&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;!-- all the logic/ content to include in that scaffold --&gt;

&lt;!-- data to be interacted with --&gt;
&lt;script&gt;
  let frames = [
    { // 0
      title:
      &quot;The final result of the image generation process.&quot;,
      description:
      'This is what we are going to build up to - the final result. The only information needed to generate this image is knowledge of the self-similar transformations that characterise it. How exactly is knowledge of these transformations applied to produce such an image though? That is what we are going to walk through step by step in this slideshow.',
      imageData: () =&gt; IFS.get(eval(preset), 250000),
    },
    { // I
      title:
      &quot;I. The initial starting point&quot;,
      description:
      &quot;We start with just one point. For simplicity's sake, the coordinates of this point are chosen to be (0,0), but it actually doesn't matter where you choose to begin. In generating these images the point that you start with is moved around so many times that the importance of that first position is, in the end, thouroughly eroded. Like the classic street magic trick where you have to follow the ball underneath the three cups, after a while it seems impossible to determine where it all began anyway. NOTE: although the starting position may appear to be different for each choice of fractal, actually the red point is always (0,0). What's going on is that in each case we are looking at a different section of the cartesian plane.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 0, {style: 'blobs', blobsSize: 3}),
    },
    { // II
      title:
      &quot;II. The very first iteration&quot;,
      description:
      &quot;&lt;i&gt;This&lt;/i&gt; is the core process. We take the position of the last point we plotted (in this case the only point) and we use one of the rules to decide where to move it to. Here the last point (the starting point) has been marked in red, and the new point is marked in black. NOTE: you may have not noticed any change between this slide and the last slide. If that is the case it is because the transformation that was applied mapped the initial position right back onto itself. &lt;b&gt;If you re-run the process&lt;/b&gt; (you can do this by clicking again on the preset you wish to load, or clicking on the canvas itself) you will see that the new position is not the same every time - a different one of the transformation rules is chosen at random each time.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 1, {style: 'lines', blobsSize: 3}),
    },
    { // III
      title:
      &quot;III. More iterations, colorised&quot;,
      description:
      &quot;We make one small change to our method while things are still simple and uncluttered: we colour the lines and the points differently according to which transformation rule was responsible for each motion. The colours themselves are not significant, but lines with the same colour correspond to movements caused by the same transformation rule. This way it's a little easier to see what's happening under the hood.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 5, {style: 'lines', color: 'last', blobsSize: 3}),
      // function call:
      // IFS.get(eval(preset), 5, {style: 'lines', color: 'last'});
    },
    { // IV
      title:
      &quot;IV. 50 Steps in, some patterns emerge.&quot;,
      description:
      &quot;Here we plot the path that our first point follows as we apply this process over and over again, more and more times. Slowly, what seems chaotic shows form. From erratic motions to repeated patterns. Though the path is far from perfectly tracing the pattern we are seeking, we start to see its characteristics in the regions that are visited and revisited.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 50, {style: 'lines', color: 'last', blobsSize: 3}),
      // function call:
      // IFS.get(eval(preset), 10-1000, {style: 'lines', color: 'last'});
    },
    { // V
      title:
      &quot;V. The output after 2000 of these random jumps&quot;,
      description:
      &quot;This is perhaps my favourite step in the process. It is absolutely clear now that these rules when applied together produce something orderly, but the resulting form is still so messy and confusing. The step that nicely straddles the unpredictable beginnings and the completely predetermined end.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 2000, {style: 'lines', color: 'last', blobsSize: 0}),
      // function call:
      // IFS.get(eval(preset), 10,0000, {style: 'lines', color: 'last'});
    },
    { // VI
      title:
      &quot;VI. What you see when you remove all the connecting lines&quot;,
      description:
      &quot;The path becomes so tangled and self-crossing that it is easier to appreciate what's going on by actually giving up on following the movements and instead just focusing the spots which were visited along the way. Less ball of thread, more breadcrumbs. As we dot around, following one transformation after another, we place a marker at each resting place, colored according to the transformation responsible for its last motion. The result is much more sparse but much more orderly. The only thing left to do now is repeat the process many more times to flesh out the picture.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 2000, {color: 'last'}),
    },
    { // VII
      title:
      &quot;VII. Cranking up the iterations from 2,000 to 100,000&quot;,
      description:
      &quot;And suddenly the shape comes into focus, and refreshing the picture seems to have little effect other than to cause the dancing of points around their already well settled places. It turns out these positions were in some way inevitable.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 100000, {color: 'last'}),
    },
    { // VIII
      title:
      &quot;VIII. Superimposing the bounding boxes to indicate the different rules&quot;,
      description:
      &quot;Here we make one last addition to our visual exposition; one box surrounding the entire input region, and then one coloured output box for each rule making up the fractal definition. In this way the impact of each transformation is made absolutely apparent.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 100000, {color: 'last', bboxes: true}),
    },
    { // IX
      title:
      &quot;IX. Ending where we started&quot;,
      description:
      &quot;By removing the didactic coloring and inclusion of bounding boxes to indicate the transformations at work, we find ourselves back where we started - the process of generating the fractal from its transformation-specification is complete.&quot;,
      imageData: () =&gt; IFS.get(eval(preset), 250000, {color: 'uniform'}),
    },
  ];
&lt;/script&gt;

&lt;!-- interaction handling --&gt;
&lt;script&gt;
  // functions
  // events / content
  let slideNum = 0;
  let preset = 'binaryTree';
  let presets = [...document.getElementById('presets').childNodes];
  let loadPreset = (e) =&gt; {
    preset = e.target.alt;
    getFrame(frames[slideNum]);
  }
  for (index in presets) {
    if(presets[index].nodeName == 'INPUT') {
      presets[index].onclick = (e) =&gt; {
        for(indexB in presets) {
            presets[indexB].style = &quot;background-color: #ddd; font-weight: lighter;&quot;
        }
        e.target.style = &quot;background-color: #ddd; font-weight: heavier;&quot;
        preset = e.target.alt;
        getFrame(frames[slideNum]);
      };
    }
  }
  let frameDescriptionContainer = document.getElementsByName('frame-description-container');
  let nextButton = document.getElementById('next-button');
  let prevButton = document.getElementById('previous-button');
  let frameDescription = document.getElementById('frame-description');
  let frameTitle = document.getElementById('frame-title');
  let frameCanvas;
  let frameContext;
  let slideControls = document.getElementById('slide-controls');
  let canvasContainer = document.getElementById('canvas-container');
  let options = 
  nextButton.onclick = () =&gt; { 
    slideNum = (slideNum + 1 + 10) % 10;
    getFrame(frames[slideNum]);
  };
  prevButton.onclick = () =&gt; { 
    slideNum = (slideNum - 1 + 10) % 10;
    getFrame(frames[slideNum]);
  };
  const getFrame = (frame) =&gt; {
    if (canvasContainer.hidden == true) {
      canvasContainer.hidden = false;
      frameCanvas = document.createElement('canvas');
      canvasContainer.appendChild(frameCanvas);
      let containerWidth = canvasContainer.offsetWidth;
      frameCanvas.style = &quot;margin-right:auto; margin-left:auto; display:block;&quot;
      frameCanvas.width = containerWidth;
      frameCanvas.height = containerWidth;
      frameCanvas.id = &quot;frame-canvas&quot;
      frameCanvas.onclick = () =&gt; paint(frameCanvas, frames[slideNum].imageData());
    }
    slideControls.hidden = false;
    frameTitle.innerHTML = frame.title;
    frameDescription.innerHTML = frame.description;
    if (preset == &quot;random&quot; || preset == &quot;mapleLeaf&quot;) {
      IFS.defaultOptions.scale = 0.7;
    } else if (preset == &quot;binaryTree&quot;) {
      IFS.defaultOptions.scale = 0.8;
    } else {
      IFS.defaultOptions.scale = 0.9;
    }
    paint(frameCanvas, frame.imageData());
  }
  const download = () =&gt; {
    
  }
&lt;/script&gt;

&lt;p&gt;&lt;input type=&quot;button&quot; id=&quot;download-prep-button&quot; value=&quot;prepare download&quot; /&gt;
&lt;br /&gt;
&lt;a id=&quot;download-link&quot; download=&quot;IFS-output-image.&quot; hidden=&quot;true&quot;&gt;
  Download
&lt;/a&gt;&lt;/p&gt;

&lt;script&gt;
  // I don't know why this doesn't work
  let downloadPrepButton = document.getElementById('download-prep-button');
  let downloadLink = document.getElementById('download-link');
  downloadPrepButton.onclick = () =&gt; {
    let imageHREF = document.getElementById('frame-canvas').getContext('2d').getImageData();
    downloadLink.href = imageHREF;
    downloadLink.hidden = false;
  }
&lt;/script&gt;</content><author><name>Joel Strouts</name></author><summary type="html">↑ Select one of the above predefined rule sets to apply procedure to ↑ Download</summary></entry></feed>